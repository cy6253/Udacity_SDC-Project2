{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file = 'train.p'\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "\n",
    "X_train, y_train = train['features'], train['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = len(X_train)\n",
    "image_shape = X_train[0].shape\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Image data shape =\", image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signnames = pd.read_csv('signnames.csv')\n",
    "signnames.set_index('ClassId',inplace=True)\n",
    "\n",
    "def get_name_from_label(label):\n",
    "    return signnames.loc[label].SignName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_gry = np.sum(X_train/3, axis=3, keepdims=True)\n",
    "\n",
    "X_train = X_train_gry\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 32, 32, 1])\n",
    "Y = tf.placeholder(tf.int32, [None])\n",
    "one_hot_Y = tf.one_hot(Y,43)\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "conv1=tf.layers.conv2d(X, 6, [5, 5], activation=tf.nn.relu)\n",
    "conv1=tf.layers.max_pooling2d(conv1, [2, 2], [2, 2])\n",
    "conv1 = tf.layers.dropout(conv1, 0.7, is_training)\n",
    "\n",
    "conv2=tf.layers.conv2d(conv1, 16, [5, 5], activation=tf.nn.relu)\n",
    "conv2=tf.layers.max_pooling2d(conv2, [2, 2], [2, 2])\n",
    "conv2 = tf.layers.dropout(conv2, 0.7, is_training)\n",
    "\n",
    "fc1 = tf.contrib.layers.flatten(conv2)\n",
    "fc1 = tf.layers.dense(fc1, 400, activation=tf.nn.relu)\n",
    "fc1 = tf.layers.dropout(fc1, 0.5, is_training)\n",
    "\n",
    "fc2 = tf.layers.dense(fc1, 800, activation=tf.nn.relu)\n",
    "fc2 = tf.layers.dropout(fc2, 0.5, is_training)\n",
    "\n",
    "logits = tf.layers.dense(fc2, 43, activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels = one_hot_Y, logits = logits))\n",
    "    optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "  \n",
    "    batch_size = 128\n",
    "    epoch = 20\n",
    "  \n",
    "    for epoch in range(epoch):\n",
    "        \n",
    "        total_cost = 0\n",
    "        for offset in range(0, len(X_train), batch_size):\n",
    "            end = offset + batch_size\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            _, cost_val = sess.run([optimizer, cost],feed_dict={X: batch_x, Y: batch_y, is_training: True})\n",
    "            total_cost += cost_val\n",
    "        print('Epoch:', '%04d' % (epoch + 1),'Avg. cost =', '{:.4f}'.format(total_cost / (len(X_train)/batch_size)))\n",
    "    print('최적화 완료!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_variables():\n",
    "\n",
    "    train()\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, 'weights/test.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_variables():\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, 'weights/test.ckpt')\n",
    "    \n",
    "    index = random.randint(0, len(X_train))\n",
    "    sample_image = X_train[index].squeeze()\n",
    "    plt.imshow(sample_image)\n",
    "    \n",
    "    sample_image = sample_image.reshape(-1, 32, 32, 1)\n",
    "    result = sess.run(tf.argmax(logits, 1), feed_dict = { X : sample_image})\n",
    "    result=result[0]\n",
    "    print(get_name_from_label(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "\n",
    "    if __name__ == '__main__' :\n",
    "        save_variables()\n",
    "        restore_variables()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
